\documentclass[journal]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{outlines}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{biblatex}
\usepackage{etoolbox}
\usepackage{csquotes}

\addbibresource{references.bib}

\begin{document}

\markboth{Military Use of Autonomous Weapons, January 2021}
{Military Use of Autonomous Vehicles}

\title{Military Use of Autonomous Weapons}
\author{William Vida, Bachelor of Science (Honours) in Software Development, Galway-Mayo Institute of Technology}

\maketitle
    
\begin{abstract}
	We are approaching a time in which the world is being more automated. One aspect of this is the use of autonomous weapons and autonomous vehicles by military forces. In the coming future, we could see a world in which warfare is not fought by soldiers but by autonomous weapons and autonomous vehicles on land, sea, and air. There are many positives to this advancement, but this also raises many questions and objections. These machines would replace most forms of soldiers on the battlefield. They would have the ability to match or beat the decision making of modern humans and not be affected by morale or fatigue which could mean the end of humans being the ones sent onto the battlefield.
\end{abstract}

\section{Introduction}
In the coming years and decades, we could see the extinction of soldiers on the battlefield as they would be replaced with autonomous vehicles (AVs) and lethal autonomous weapons (LAWs). AVs or LAWs are capable of making decisions without any human interaction. A November 2012 directive numbered 3000.09 by the United States Department of Defence defines an autonomous weapon system as:
\begin{quote}
	A weapon system that, once activated, can select and engage targets without further intervention by a human operator. This includes human-supervised autonomous weapon systems that are designed to allow human operators to override operation of the weapon system but can select and engage targets without further human input after activation \cite{us2012autonomy} \cite{anderson2013law}.
\end{quote}
However, it must be said that there is no universally accepted definition of what an autonomous system is. AVs and LAWs rely on artificial intelligence to make informed decisions on what to do \cite{taeihagh2019governing}. Fully autonomous weapons would remove all human control on whether deadly force should be authorised. At the moment, most of the news on AVs are about civilian use, usually about self-driving cars. Most unmanned vehicles that are used today are not fully autonomous and still need human supervision or are controlled by humans.

\section{History}
AVs and LAWs are a recent phenomenon. However, throughout history and especially modern history, there have been attempts to send unmanned vehicles instead of soldiers into combat with varying degrees of success.

The first flight in history was made by the Wright Brothers in December 1903. Although aircraft technology was still quite primitive in World War 1, in 1915, Elmer Sperry and Peter Cooper Hewitt developed the Hewitt-Sperry Automatic Airplane for the United States Navy. It could carry more than 130 kilograms of explosives, travel eighty kilometres an hour and it had a distance of at most 160 kilometres \cite{whitmore2016evolution}.

During the interwar years of 1919-1938, saw the rise of the militarisation of multiple nations leading to rapid technological advancement in terms of their military. In 1920, the United States Army financed the development of a cheap aircraft that was able to deliver messages between headquarters instead of messengers. A robotic version was developed which could remotely fly from one headquarters to another using radio control. Although it was a great achievement of its era, the concept was ahead of its time. In 1933, the British flew a radio-controlled Fairey Queen \cite{zaloga2011unmanned}.

When the Soviet Union invaded Finland in November 1939 during World War 2, the Soviet Union deployed TT-26 teletanks which were unmanned remote controlled tanks. The teletanks were controlled using a radio tank at a distance of 500 to 1,500 metres. The teletanks were equipped with machine guns and flamethrowers. They could also carry 200-700 kilograms of bombs. During World War 2, Germany developed the Goliath Tracked Mine. The Goliath Tracked Mine was a small, one-metre long single-use vehicle that carried seventy-five kilograms of explosives. It was used mainly for anti-tank purposes, anti-infrastructure and for destroying bridges. It was connected to a control box by telephone wires. Even though more than seven thousand units were built, due to their relatively high cost, thin armour, and low speed they have not been deemed a success \cite{villar2016unmanned}.

\section{Levels of Autonomy}
Similar to the lack of universally accepted for the definition of LAWs, there is no universally accepted scale for the levels of autonomy for autonomous systems. Most autonomous scales have the lowest form of autonomy being an unmanned vehicle being controlled by a human to the highest level of autonomy wherein an unmanned vehicle acts on itself taking no human intervention or human input to perform a task \cite{anderson2015autonomous}.

In 1978, Thomas B. Sheridan and W. L. Verplank developed a 10 level scale showing the different types of autonomy \cite{sheridan1978human}: 
\begin{enumerate} 
	\item The human operator does the task until the human operator gives control to the computer to fulfil the task.
	\item The computer helps to determine the options that could be taken.
	\item The computer helps to determine the options and suggests one. The human operator may or may not follow through on the options givens.
	\item The computer selects an action and the human operator may or may not execute the action.
	\item The computer selects an action and implements it if the human operator approves the action.
	\item The computer selects an action and informs the human operator if the human operator wants to cancel the action.
	\item The computer does the whole task and tells the human operator what it did.
	\item The computer does the whole job, and it tells the human operator what it did only if the human operator specifically asks.
	\item The computer does the whole job and the computer decides if the human operator should be told about the job.
	\item The computer decides if the whole job should be done. The computer decides if the human operator should be told about the job.
\end{enumerate}

\section{Benefits of Using Autonomous Weapons}
There are many benefits when it comes to using LAWs instead of soldiers in combat. LAWs act as a force multiplier, meaning that fewer autonomous systems than soldiers are needed for an operation and the effectiveness of each system is larger. LAWs and unmanned vehicles would be able to access areas that were not previously accessible, and LAWs can greatly reduce the need for human soldiers to be present on the battlefield, thus reducing human causalities \cite{etzioni2017pros}. This can politically help governments as this might allow them to avoid the pushback, dislike, and potential unrest of policies such as conscription by the general populace by sending LAWs to fight in wars instead. During the Vietnam War, conscription, or the draft as it is also known as in the United States, many people refused to be deployed, evaded the draft, or simply migrated from the United States to avoid being sent to fight in Vietnam, where more than 50,000 Americans died.

In 2013, an article stated that the Pentagon spent \$850,000 a year per soldier in Afghanistan. A Foster-Miller TALON, which is a small, remotely operated military ground robot cost \$230,000 even when it is equipped with weapons such as machine guns and grenade launchers \cite{etzioni2017pros}. Human soldiers need to be paid and cost money before, during and after they have served their time and can only serve until a certain age when their body can no longer cope with the physicality of combat or if they are injured badly enough that a return to combat is unfeasible. Soldiers are also affected by morale, the will to fight and fatigue while LAWs are not affected by any of these. When soldiers suffer injuries and/or mental disorders such as the loss of ligaments or post-traumatic stress disorder, the military usually has to take care of these situations and the military is usually responsible for any medical expenses that may arise. With LAWs, the research, development, purchase, and maintenance still have to be done by the military, although it will probably be financially better for militaries to gradually replace human soldiers with LAWs in the future.

LAWs would have the ability of precision strike and execute operations in massively coordinated movement, better than that of human-controlled vehicles. LAWs can be equipped with the latest, top-secret weapons the military has to offer. They would have the ability to analyse situations in seconds or even milliseconds, make decisions based on that information and execute that operation. Military commanders today spend many hours calculating the blast effects of military strikes. LAWs would be able to do this in a very short time. It would be unthinkable for human soldiers to make calculations like these during combat under intense pressure \cite{guetlein2005lethal}.

\section{Responsibility}
There is a complex debate when it comes to the question of who will be responsible for the actions of AVs and LAWs. There has been a range of positions that go from arguing that it will not be possible to hold humans to account for the behaviours of autonomous systems to those that say that autonomous systems themselves will be held responsible. Others argue that the responsibility will be shared between humans and autonomous systems or that humans will be responsible for every action done by autonomous systems \cite{noorman2014negotiating}.

Many studies have shown that humans assign responsibility to computers. In one study, 21 per cent of those who participated in the study held a computer responsible for wrong decisions made in two situations wherein medical radiation procedures in which several patients were over-radiated and an assessment of jobseekers in which the computer refused eligible candidates. Another study asked participants if a mobile robot performing a delivery task was responsible for errors made and if the robot was to blame for the difficulties faced in the completion of the delivery. The results showed that the participants involved blamed the mobile robots and held them responsible, but it varied on the two levels of autonomy that were used. In the low-level mode, the mobile robot asked the humans whether or not to complete one part of the task while in the high-level mode, the mobile robot decided on its own whether or not to proceed \cite{Hellstrom2013-HELOTM-2}.

In a free and democratic state, the people elect politicians. This gives them a lot of responsibility and a lot of power, especially those who are at the top of the political hierarchy. However, politicians do not always act in the best interest of the people and/or their constituents. This also means that given enough votes and support, the politicians can decide to go to war. The politicians, of course, do not fight wars themselves, instead, that task is given to the military and their commanders who give orders to the lower ranks and soldiers who carry out the operations. In war, the responsibility is not the same for all parties as the higher ranks in the military have more power and hence more responsibility \cite{Hellstrom2013-HELOTM-2}.

An important barrier that could hinder the development and adoption of LAWs is their current lack of ability to consistently differentiate between military personnel and civilians. The Geneva Conventions state that attacks must be against military targets and not civilians. Another issue that can arise is what is the definition of a civilian. There may be situations where civilians take part in combat making it unclear if such persons should fall under the category of "combatants" or "non-combatants" \cite{umbrello2020future}. Today, even when military strikes are done with the best intentions as to make sure no civilian is hurt when targeting enemy military combatants, more often than not, civilians are still injured and killed. This does not mean that LAWs will be able to guarantee that no non-combatants will be uninjured. In this case, LAWs are governed by the principle of proportionality which requires that before engagement, the potential risk to civilians is measured against the expected military benefit to be gained from the attack. However, these factors would be very subjective on the values that may be applied. As the values may be dependent on moral decision making, one can argue based on that LAWs should not be allowed to make lethal actions and decisions on their own as their lack of ability to differentiate between military and non-military targets. Because of these factors, humans should monitor LAWs and they should always be allowed to make the final and lethal call \cite{umbrello2020future}.

\section{Law}
Arguments over whether or not LAWs should be allowed in warfare are similar to more than a century ago when there was a debate on whether or not submarines and military aircraft should be allowed to be used in war. An objection that was used then and today is that they reduce the risk to those who are using them. Thus, making it dishonourable and unfair to those using them from a safe distance whether it is using UAVs, missiles, or LAWs \cite{anderson2013law}.

If a new weapon is developed, Article 36 of the Additional Protocol to the Geneva Conventions states:
\begin{quote}
	In the study, development, acquisition or adoption of a new weapon, means or method of warfare, a High Contracting Party is under an obligation to determine whether its employment would, in some or all circumstances, be prohibited by this Protocol or by any other rule of international law applicable to the High Contracting Party \cite{anderson2015autonomous}.
\end{quote}
Currently, there are no international treaties that ban the development or use of LAWs. Many of the great powers of the world, such as the United States, Russia, and China, are actively pursuing the research and development of LAWs. An international treaty banned such weapons could be successful. Poison gas was used extensively by all sides during World War 1. During the 1920s the Geneva Protocol was signed which banned the use of poison and other forms of gas in warfare. This treaty has been very successful in preventing the use of gas in warfare ever since but the Ottawa Treaty which bans the use of land mines has been signed by most countries but major powers such as the United States, Russia, and China \cite{umbrello2020future}. This shows that nations will only go as far as to ban the use of weapons that seem advantageous whether it be militarily, politically, or economically to their wars.

\section{Conclusion}
Humans already are inclined to give responsibilities and apply blame to computers and as the world becomes more automated and more powerful autonomous systems are built, this inclination will only increase. Today, we need to be discussing morality questions on autonomous entities and not when they are already mainstream or are nearly as intelligent as humans \cite{Hellstrom2013-HELOTM-2}.

The scenes in science fiction movies where robots fight each other on the battlefield seem to be a reality in the coming future. We are approaching an era where automation is becoming more commonplace for civilians while militarily LAWs will reduce the causalities suffered by militaries who possess and use them. No more will we see soldiers being sent to halfway around the world to fight in places like Korea, Vietnam, Afghanistan, or Iraq, but instead the politicians will mostly send autonomous machines to do the work that was done by humans in the past and LAWs will be better in nearly every aspect than humans. LAWs may offer a zero casualty war between those that use them. Though this does not necessarily mean the end of human responsibility \cite{guetlein2005lethal}. Due to the capabilities of LAWs, they have the potential to change the type of war that mankind has known throughout its history. This does not come without its controversy and the lack of definitive law on the matter. Maybe nations will see the potential threat that LAWs could cause to both sides, similar to poison gas and ban these systems though this is unlikely. But because of the complexity involved in differentiating a combatant to a non-combatant, it may be a very long time before we see a fully autonomous system involved in armed conflicts.

\printbibliography

\end{document}
